{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d0a1f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11 CSV files.\n",
      "[1/11] Processed bengaluru_combined.csv (1827 rows)\n",
      "[2/11] Processed chennai_combined.csv (1827 rows)\n",
      "[3/11] Processed delhi_combined.csv (1827 rows)\n",
      "[4/11] Processed gwalior_combined.csv (1827 rows)\n",
      "[5/11] Processed hyderabad_combined.csv (1827 rows)\n",
      "[6/11] Processed jaipur_combined.csv (1827 rows)\n",
      "[7/11] Processed kolkata_combined.csv (1827 rows)\n",
      "[8/11] Processed lucknow_combined.csv (1827 rows)\n",
      "[9/11] Processed mumbai_combined.csv (1827 rows)\n",
      "⚠️ Skipped data/stations_csvs\\stations_info.csv (no relevant columns found)\n",
      "[11/11] Processed visakhapatnam_combined.csv (1827 rows)\n",
      "\n",
      "✅ Done! Fixed merged file saved to: data/stations_combined.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "def load_pm_pollutants_fixed(dir_path=\"data/stations_csvs\", out_file=\"data/stations_combined.csv\"):\n",
    "    files = glob.glob(os.path.join(dir_path, \"*.csv\"))\n",
    "    print(f\"Found {len(files)} CSV files.\")\n",
    "    os.makedirs(os.path.dirname(out_file), exist_ok=True)\n",
    "\n",
    "    first = True\n",
    "    for i, f in enumerate(files, 1):\n",
    "        try:\n",
    "            # Read column headers first\n",
    "            cols = [c.strip() for c in pd.read_csv(f, nrows=0).columns]\n",
    "\n",
    "            # Detect possible matching column names\n",
    "            mapping = {}\n",
    "            for c in cols:\n",
    "                c_lower = c.lower()\n",
    "                if \"date\" in c_lower or \"time\" in c_lower:\n",
    "                    mapping[c] = \"Timestamp\"\n",
    "                elif \"pm2\" in c_lower:\n",
    "                    mapping[c] = \"PM2.5\"\n",
    "                elif \"pm10\" in c_lower:\n",
    "                    mapping[c] = \"PM10\"\n",
    "                elif \"o3\" in c_lower or \"ozone\" in c_lower:\n",
    "                    mapping[c] = \"O3\"\n",
    "                elif \"co\" in c_lower and not \"co2\" in c_lower:\n",
    "                    mapping[c] = \"CO\"\n",
    "\n",
    "            if not mapping:\n",
    "                print(f\"⚠️ Skipped {f} (no relevant columns found)\")\n",
    "                continue\n",
    "\n",
    "            df = pd.read_csv(f, usecols=mapping.keys(), encoding_errors=\"ignore\")\n",
    "            df.rename(columns=mapping, inplace=True)\n",
    "            df[\"StationFile\"] = os.path.basename(f)\n",
    "\n",
    "            # Make sure all columns exist\n",
    "            for col in [\"Timestamp\", \"PM2.5\", \"PM10\", \"O3\", \"CO\"]:\n",
    "                if col not in df.columns:\n",
    "                    df[col] = None\n",
    "\n",
    "            if first:\n",
    "                df.to_csv(out_file, index=False)\n",
    "                first = False\n",
    "            else:\n",
    "                df.to_csv(out_file, mode=\"a\", index=False, header=False)\n",
    "\n",
    "            print(f\"[{i}/{len(files)}] Processed {os.path.basename(f)} ({len(df)} rows)\")\n",
    "            del df\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Skipped {f}: {e}\")\n",
    "\n",
    "    print(f\"\\n✅ Done! Fixed merged file saved to: {out_file}\")\n",
    "\n",
    "# Run this to rebuild Kaggle merged dataset\n",
    "load_pm_pollutants_fixed(\"data/stations_csvs\", \"data/stations_combined.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "468685aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>PM2.5</th>\n",
       "      <th>PM10</th>\n",
       "      <th>CO</th>\n",
       "      <th>O3</th>\n",
       "      <th>StationFile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01-01-2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bengaluru_combined.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02-01-2020</td>\n",
       "      <td>43.67</td>\n",
       "      <td>134.00</td>\n",
       "      <td>0.91</td>\n",
       "      <td>21.82</td>\n",
       "      <td>bengaluru_combined.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>03-01-2020</td>\n",
       "      <td>30.58</td>\n",
       "      <td>74.42</td>\n",
       "      <td>0.96</td>\n",
       "      <td>23.31</td>\n",
       "      <td>bengaluru_combined.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04-01-2020</td>\n",
       "      <td>66.35</td>\n",
       "      <td>155.68</td>\n",
       "      <td>2.54</td>\n",
       "      <td>29.70</td>\n",
       "      <td>bengaluru_combined.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>05-01-2020</td>\n",
       "      <td>48.00</td>\n",
       "      <td>99.13</td>\n",
       "      <td>1.14</td>\n",
       "      <td>31.01</td>\n",
       "      <td>bengaluru_combined.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>06-01-2020</td>\n",
       "      <td>23.75</td>\n",
       "      <td>63.34</td>\n",
       "      <td>1.08</td>\n",
       "      <td>25.82</td>\n",
       "      <td>bengaluru_combined.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>07-01-2020</td>\n",
       "      <td>24.67</td>\n",
       "      <td>72.00</td>\n",
       "      <td>0.98</td>\n",
       "      <td>30.37</td>\n",
       "      <td>bengaluru_combined.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>08-01-2020</td>\n",
       "      <td>34.18</td>\n",
       "      <td>79.06</td>\n",
       "      <td>0.99</td>\n",
       "      <td>29.61</td>\n",
       "      <td>bengaluru_combined.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>09-01-2020</td>\n",
       "      <td>41.61</td>\n",
       "      <td>98.00</td>\n",
       "      <td>1.11</td>\n",
       "      <td>30.97</td>\n",
       "      <td>bengaluru_combined.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10-01-2020</td>\n",
       "      <td>38.95</td>\n",
       "      <td>97.70</td>\n",
       "      <td>0.97</td>\n",
       "      <td>31.89</td>\n",
       "      <td>bengaluru_combined.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Timestamp  PM2.5    PM10    CO     O3             StationFile\n",
       "0  01-01-2020    NaN     NaN   NaN    NaN  bengaluru_combined.csv\n",
       "1  02-01-2020  43.67  134.00  0.91  21.82  bengaluru_combined.csv\n",
       "2  03-01-2020  30.58   74.42  0.96  23.31  bengaluru_combined.csv\n",
       "3  04-01-2020  66.35  155.68  2.54  29.70  bengaluru_combined.csv\n",
       "4  05-01-2020  48.00   99.13  1.14  31.01  bengaluru_combined.csv\n",
       "5  06-01-2020  23.75   63.34  1.08  25.82  bengaluru_combined.csv\n",
       "6  07-01-2020  24.67   72.00  0.98  30.37  bengaluru_combined.csv\n",
       "7  08-01-2020  34.18   79.06  0.99  29.61  bengaluru_combined.csv\n",
       "8  09-01-2020  41.61   98.00  1.11  30.97  bengaluru_combined.csv\n",
       "9  10-01-2020  38.95   97.70  0.97  31.89  bengaluru_combined.csv"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_kaggle = pd.read_csv(\"data/stations_combined.csv\", on_bad_lines=\"skip\", low_memory=False)\n",
    "merged_kaggle.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7c207be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Home\\AppData\\Local\\Temp\\ipykernel_22016\\995085232.py:1: DtypeWarning: Columns (4,5,6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  city_df = pd.read_csv(\"data/cities_combined.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Combined dataset shape: (14313933, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>PM2.5</th>\n",
       "      <th>PM10</th>\n",
       "      <th>O3</th>\n",
       "      <th>CO</th>\n",
       "      <th>Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>KaggleStation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>43.67</td>\n",
       "      <td>134.00</td>\n",
       "      <td>21.82</td>\n",
       "      <td>0.91</td>\n",
       "      <td>KaggleStation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-03-01</td>\n",
       "      <td>30.58</td>\n",
       "      <td>74.42</td>\n",
       "      <td>23.31</td>\n",
       "      <td>0.96</td>\n",
       "      <td>KaggleStation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>66.35</td>\n",
       "      <td>155.68</td>\n",
       "      <td>29.7</td>\n",
       "      <td>2.54</td>\n",
       "      <td>KaggleStation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-05-01</td>\n",
       "      <td>48.00</td>\n",
       "      <td>99.13</td>\n",
       "      <td>31.01</td>\n",
       "      <td>1.14</td>\n",
       "      <td>KaggleStation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Timestamp  PM2.5    PM10     O3    CO         Source\n",
       "0 2020-01-01    NaN     NaN    NaN   NaN  KaggleStation\n",
       "1 2020-02-01  43.67  134.00  21.82  0.91  KaggleStation\n",
       "2 2020-03-01  30.58   74.42  23.31  0.96  KaggleStation\n",
       "3 2020-04-01  66.35  155.68   29.7  2.54  KaggleStation\n",
       "4 2020-05-01  48.00   99.13  31.01  1.14  KaggleStation"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_df = pd.read_csv(\"data/cities_combined.csv\")\n",
    "\n",
    "# Make sure Timestamp format matches\n",
    "for df in [merged_kaggle, city_df]:\n",
    "    for col in df.columns:\n",
    "        if \"time\" in col.lower() or \"date\" in col.lower():\n",
    "            df.rename(columns={col: \"Timestamp\"}, inplace=True)\n",
    "            break\n",
    "    df[\"Timestamp\"] = pd.to_datetime(df[\"Timestamp\"], errors=\"coerce\")\n",
    "\n",
    "merged_kaggle[\"Source\"] = \"KaggleStation\"\n",
    "city_df[\"Source\"] = \"CityCombined\"\n",
    "\n",
    "keep_cols = [\"Timestamp\", \"PM2.5\", \"PM10\", \"O3\", \"CO\", \"Source\"]\n",
    "for col in keep_cols:\n",
    "    if col not in city_df.columns:\n",
    "        city_df[col] = None\n",
    "\n",
    "combined_df = pd.concat([merged_kaggle[keep_cols], city_df[keep_cols]], ignore_index=True)\n",
    "print(\"✅ Combined dataset shape:\", combined_df.shape)\n",
    "combined_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc7e96f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Home\\AppData\\Local\\Temp\\ipykernel_22016\\658508099.py:7: DtypeWarning: Columns (4,5,6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  city_df = pd.read_csv(\"data/cities_combined.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kaggle dataset shape: (18270, 6)\n",
      "City dataset shape: (14295663, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>PM2.5</th>\n",
       "      <th>PM10</th>\n",
       "      <th>CO</th>\n",
       "      <th>O3</th>\n",
       "      <th>StationFile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01-01-2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bengaluru_combined.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02-01-2020</td>\n",
       "      <td>43.67</td>\n",
       "      <td>134.00</td>\n",
       "      <td>0.91</td>\n",
       "      <td>21.82</td>\n",
       "      <td>bengaluru_combined.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>03-01-2020</td>\n",
       "      <td>30.58</td>\n",
       "      <td>74.42</td>\n",
       "      <td>0.96</td>\n",
       "      <td>23.31</td>\n",
       "      <td>bengaluru_combined.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Timestamp  PM2.5    PM10    CO     O3             StationFile\n",
       "0  01-01-2020    NaN     NaN   NaN    NaN  bengaluru_combined.csv\n",
       "1  02-01-2020  43.67  134.00  0.91  21.82  bengaluru_combined.csv\n",
       "2  03-01-2020  30.58   74.42  0.96  23.31  bengaluru_combined.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Timestamp.1</th>\n",
       "      <th>PM2.5</th>\n",
       "      <th>PM10</th>\n",
       "      <th>CO</th>\n",
       "      <th>O3</th>\n",
       "      <th>StationFile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-07-01 10:00:00</td>\n",
       "      <td>2016-07-01 11:00:00</td>\n",
       "      <td>10.67</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.48</td>\n",
       "      <td>14.5</td>\n",
       "      <td>AP001.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-07-01 11:00:00</td>\n",
       "      <td>2016-07-01 12:00:00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.49</td>\n",
       "      <td>15.0</td>\n",
       "      <td>AP001.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-07-01 12:00:00</td>\n",
       "      <td>2016-07-01 13:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AP001.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Timestamp          Timestamp.1  PM2.5  PM10    CO    O3  \\\n",
       "0  2016-07-01 10:00:00  2016-07-01 11:00:00  10.67  39.0  0.48  14.5   \n",
       "1  2016-07-01 11:00:00  2016-07-01 12:00:00   2.00  39.0  0.49  15.0   \n",
       "2  2016-07-01 12:00:00  2016-07-01 13:00:00    NaN   NaN   NaN   NaN   \n",
       "\n",
       "  StationFile  \n",
       "0   AP001.csv  \n",
       "1   AP001.csv  \n",
       "2   AP001.csv  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the new Kaggle dataset (the fixed one)\n",
    "kaggle_df = pd.read_csv(\"data/stations_combined.csv\", on_bad_lines=\"skip\", low_memory=False)\n",
    "\n",
    "# Load your Combined City Pollution dataset\n",
    "city_df = pd.read_csv(\"data/cities_combined.csv\")\n",
    "\n",
    "print(\"Kaggle dataset shape:\", kaggle_df.shape)\n",
    "print(\"City dataset shape:\", city_df.shape)\n",
    "\n",
    "# Show first few rows from both\n",
    "display(kaggle_df.head(3))\n",
    "display(city_df.head(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16fd0286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Combined dataset shape: (14302863, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>PM2.5</th>\n",
       "      <th>PM10</th>\n",
       "      <th>O3</th>\n",
       "      <th>CO</th>\n",
       "      <th>Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>KaggleStation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>43.67</td>\n",
       "      <td>134.00</td>\n",
       "      <td>21.82</td>\n",
       "      <td>0.91</td>\n",
       "      <td>KaggleStation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-03-01</td>\n",
       "      <td>30.58</td>\n",
       "      <td>74.42</td>\n",
       "      <td>23.31</td>\n",
       "      <td>0.96</td>\n",
       "      <td>KaggleStation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>66.35</td>\n",
       "      <td>155.68</td>\n",
       "      <td>29.7</td>\n",
       "      <td>2.54</td>\n",
       "      <td>KaggleStation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-05-01</td>\n",
       "      <td>48.00</td>\n",
       "      <td>99.13</td>\n",
       "      <td>31.01</td>\n",
       "      <td>1.14</td>\n",
       "      <td>KaggleStation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Timestamp  PM2.5    PM10     O3    CO         Source\n",
       "0 2020-01-01    NaN     NaN    NaN   NaN  KaggleStation\n",
       "1 2020-02-01  43.67  134.00  21.82  0.91  KaggleStation\n",
       "2 2020-03-01  30.58   74.42  23.31  0.96  KaggleStation\n",
       "3 2020-04-01  66.35  155.68   29.7  2.54  KaggleStation\n",
       "4 2020-05-01  48.00   99.13  31.01  1.14  KaggleStation"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalize timestamp names\n",
    "for df in [kaggle_df, city_df]:\n",
    "    for col in df.columns:\n",
    "        if \"time\" in col.lower() or \"date\" in col.lower():\n",
    "            df.rename(columns={col: \"Timestamp\"}, inplace=True)\n",
    "            break\n",
    "\n",
    "# Force datetime conversion + DROP invalid timestamps\n",
    "for df in [kaggle_df, city_df]:\n",
    "    df[\"Timestamp\"] = pd.to_datetime(df[\"Timestamp\"], errors=\"coerce\")\n",
    "    df.dropna(subset=[\"Timestamp\"], inplace=True)\n",
    "\n",
    "# Add source column\n",
    "kaggle_df[\"Source\"] = \"KaggleStation\"\n",
    "city_df[\"Source\"] = \"CityCombined\"\n",
    "\n",
    "# Keep only the matching pollutant columns\n",
    "keep_cols = [\"Timestamp\", \"PM2.5\", \"PM10\", \"O3\", \"CO\", \"Source\"]\n",
    "\n",
    "# Add missing columns\n",
    "for col in keep_cols:\n",
    "    if col not in city_df.columns:\n",
    "        city_df[col] = None\n",
    "\n",
    "# Merge both datasets\n",
    "combined_df = pd.concat(\n",
    "    [kaggle_df[keep_cols], city_df[keep_cols]],\n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "print(\"✅ Combined dataset shape:\", combined_df.shape)\n",
    "combined_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b70e7a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp          0\n",
      "PM2.5        3829690\n",
      "PM10         4422984\n",
      "O3           3294466\n",
      "CO           3267519\n",
      "Source             0\n",
      "dtype: int64\n",
      "✅ After cleaning: (12134002, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>PM2.5</th>\n",
       "      <th>PM10</th>\n",
       "      <th>O3</th>\n",
       "      <th>CO</th>\n",
       "      <th>Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>43.67</td>\n",
       "      <td>134.00</td>\n",
       "      <td>21.82</td>\n",
       "      <td>0.91</td>\n",
       "      <td>KaggleStation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-03-01</td>\n",
       "      <td>30.58</td>\n",
       "      <td>74.42</td>\n",
       "      <td>23.31</td>\n",
       "      <td>0.96</td>\n",
       "      <td>KaggleStation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>66.35</td>\n",
       "      <td>155.68</td>\n",
       "      <td>29.7</td>\n",
       "      <td>2.54</td>\n",
       "      <td>KaggleStation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-05-01</td>\n",
       "      <td>48.00</td>\n",
       "      <td>99.13</td>\n",
       "      <td>31.01</td>\n",
       "      <td>1.14</td>\n",
       "      <td>KaggleStation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>23.75</td>\n",
       "      <td>63.34</td>\n",
       "      <td>25.82</td>\n",
       "      <td>1.08</td>\n",
       "      <td>KaggleStation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Timestamp  PM2.5    PM10     O3    CO         Source\n",
       "1 2020-02-01  43.67  134.00  21.82  0.91  KaggleStation\n",
       "2 2020-03-01  30.58   74.42  23.31  0.96  KaggleStation\n",
       "3 2020-04-01  66.35  155.68   29.7  2.54  KaggleStation\n",
       "4 2020-05-01  48.00   99.13  31.01  1.14  KaggleStation\n",
       "5 2020-06-01  23.75   63.34  25.82  1.08  KaggleStation"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check missing values\n",
    "print(combined_df.isna().sum())\n",
    "\n",
    "# Drop rows with completely empty pollutant data\n",
    "combined_df = combined_df.dropna(subset=[\"PM2.5\", \"PM10\", \"O3\", \"CO\"], how=\"all\")\n",
    "\n",
    "# Fill remaining missing values with median (optional)\n",
    "combined_df[[\"PM2.5\", \"PM10\", \"O3\", \"CO\"]] = combined_df[[\"PM2.5\", \"PM10\", \"O3\", \"CO\"]].fillna(\n",
    "    combined_df.median(numeric_only=True)\n",
    ")\n",
    "\n",
    "print(\"✅ After cleaning:\", combined_df.shape)\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e0d7631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved clean dataset: data/master_airquality_clean.csv\n"
     ]
    }
   ],
   "source": [
    "combined_df.to_csv(\"data/master_airquality_clean.csv\", index=False)\n",
    "print(\"✅ Saved clean dataset: data/master_airquality_clean.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31b0ed5",
   "metadata": {},
   "source": [
    "#IMPORTANT PROJECT INSTALLATION DETAILS AFTER THIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a894b1b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Usage:   \n",
      "  pip install [options] <requirement specifier> [package-index-options] ...\n",
      "  pip install [options] -r <requirements file> [package-index-options] ...\n",
      "  pip install [options] [-e] <vcs project url> ...\n",
      "  pip install [options] [-e] <local project path> ...\n",
      "  pip install [options] <archive url/path> ...\n",
      "\n",
      "no such option: -m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in e:\\5th sem data\\ai254ta-machine learning operations(mlops)\\mlops_project\\venv\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy in e:\\5th sem data\\ai254ta-machine learning operations(mlops)\\mlops_project\\venv\\lib\\site-packages (2.3.5)\n",
      "Requirement already satisfied: scikit-learn in e:\\5th sem data\\ai254ta-machine learning operations(mlops)\\mlops_project\\venv\\lib\\site-packages (1.7.2)\n",
      "Requirement already satisfied: xgboost in e:\\5th sem data\\ai254ta-machine learning operations(mlops)\\mlops_project\\venv\\lib\\site-packages (3.1.2)\n",
      "Requirement already satisfied: joblib in e:\\5th sem data\\ai254ta-machine learning operations(mlops)\\mlops_project\\venv\\lib\\site-packages (1.5.2)\n",
      "Requirement already satisfied: matplotlib in e:\\5th sem data\\ai254ta-machine learning operations(mlops)\\mlops_project\\venv\\lib\\site-packages (3.10.7)\n",
      "Requirement already satisfied: seaborn in e:\\5th sem data\\ai254ta-machine learning operations(mlops)\\mlops_project\\venv\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in e:\\5th sem data\\ai254ta-machine learning operations(mlops)\\mlops_project\\venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in e:\\5th sem data\\ai254ta-machine learning operations(mlops)\\mlops_project\\venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in e:\\5th sem data\\ai254ta-machine learning operations(mlops)\\mlops_project\\venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.8.0 in e:\\5th sem data\\ai254ta-machine learning operations(mlops)\\mlops_project\\venv\\lib\\site-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in e:\\5th sem data\\ai254ta-machine learning operations(mlops)\\mlops_project\\venv\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in e:\\5th sem data\\ai254ta-machine learning operations(mlops)\\mlops_project\\venv\\lib\\site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in e:\\5th sem data\\ai254ta-machine learning operations(mlops)\\mlops_project\\venv\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in e:\\5th sem data\\ai254ta-machine learning operations(mlops)\\mlops_project\\venv\\lib\\site-packages (from matplotlib) (4.61.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in e:\\5th sem data\\ai254ta-machine learning operations(mlops)\\mlops_project\\venv\\lib\\site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in e:\\5th sem data\\ai254ta-machine learning operations(mlops)\\mlops_project\\venv\\lib\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in e:\\5th sem data\\ai254ta-machine learning operations(mlops)\\mlops_project\\venv\\lib\\site-packages (from matplotlib) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in e:\\5th sem data\\ai254ta-machine learning operations(mlops)\\mlops_project\\venv\\lib\\site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: six>=1.5 in e:\\5th sem data\\ai254ta-machine learning operations(mlops)\\mlops_project\\venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Invalid requirement: '#': Expected package name at the start of dependency specifier\n",
      "    #\n",
      "    ^\n"
     ]
    }
   ],
   "source": [
    "# pip install (run in a notebook cell with `!` or in terminal)\n",
    "!pip install --upgrade pip # python -m pip install --upgrade pip\n",
    "!pip install pandas numpy scikit-learn xgboost joblib matplotlib seaborn\n",
    "!pip install aif360 metaflow wandb bentoml whylabs-sdk fastparquet # pip install whylogs whylabs-client whylabs-toolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36336576",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Home\\AppData\\Local\\Temp\\ipykernel_22016\\4248515241.py:25: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df[ts_col] = pd.to_datetime(df[ts_col], errors='coerce', dayfirst=True, infer_datetime_format=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp-like columns found: ['Timestamp', 'Timestamp.1']\n",
      "After first parse, NaT fraction = 0.000\n"
     ]
    }
   ],
   "source": [
    "# Fix Timestamp -> datetime, create time features, and show diagnostics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# load dataset if not in memory\n",
    "try:\n",
    "    df  # if df exists, we use it\n",
    "except NameError:\n",
    "    df = pd.read_csv(\"data/master_airquality_clean.csv\", low_memory=False)\n",
    "\n",
    "# Find likely timestamp column(s)\n",
    "possible_ts = [c for c in df.columns if any(k in c.lower() for k in [\"time\",\"date\",\"timestamp\"])]\n",
    "print(\"Timestamp-like columns found:\", possible_ts)\n",
    "\n",
    "# If 'Timestamp' already present but not datetime, try to convert it.\n",
    "if 'Timestamp' in df.columns:\n",
    "    ts_col = 'Timestamp'\n",
    "else:\n",
    "    ts_col = possible_ts[0] if possible_ts else None\n",
    "\n",
    "if ts_col is None:\n",
    "    raise RuntimeError(\"No timestamp-like column found. Please tell me the column names: \" + \", \".join(df.columns))\n",
    "\n",
    "# Convert robustly (try several formats)\n",
    "df[ts_col] = pd.to_datetime(df[ts_col], errors='coerce', dayfirst=True, infer_datetime_format=True)\n",
    "\n",
    "# If too many NaT, try alternate parsing (common alternative formats)\n",
    "nat_frac = df[ts_col].isna().mean()\n",
    "print(f\"After first parse, NaT fraction = {nat_frac:.3f}\")\n",
    "\n",
    "if nat_frac > 0.25:\n",
    "    # try parsing with no dayfirst\n",
    "    df[ts_col] = pd.to_datetime(df[ts_col].astype(str), errors='coerce', dayfirst=False, infer_datetime_format=True)\n",
    "    nat_frac2 = df[ts_col].isna().mean()\n",
    "    print(f\"After second parse (dayfirst=False), NaT fraction = {nat_frac2:.3f}\")\n",
    "\n",
    "# Rename unified column to 'Timestamp'\n",
    "df.rename(columns={ts_col: 'Timestamp'}, inplace=True)\n",
    "\n",
    "# Drop rows with missing Timestamp (can't use them for time features)\n",
    "n_before = len(df)\n",
    "df = df[~df['Timestamp'].isna()].copy()\n",
    "n_after = len(df)\n",
    "print(f\"Dropped {n_before - n_after} rows with unparseable Timestamp\")\n",
    "\n",
    "# Create time features\n",
    "df['hour'] = df['Timestamp'].dt.hour\n",
    "df['dayofweek'] = df['Timestamp'].dt.dayofweek\n",
    "df['month'] = df['Timestamp'].dt.month\n",
    "\n",
    "# Ensure numeric pollutant columns exist\n",
    "for col in ['PM2.5','PM10','O3','CO']:\n",
    "    if col not in df.columns:\n",
    "        df[col] = np.nan\n",
    "    else:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "# Quick diagnostics\n",
    "print(\"Dataset now has shape:\", df.shape)\n",
    "print(\"Timestamp min/max:\", df['Timestamp'].min(), \"/\", df['Timestamp'].max())\n",
    "display(df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcea4c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure features list exists\n",
    "features = ['PM10', 'O3', 'CO', 'hour', 'dayofweek', 'month']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc2d11f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (3817005, 6) Test: (954251, 6)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "n = len(df)\n",
    "test_size = int(0.2 * n)\n",
    "train_df = df.iloc[:n - test_size].copy()\n",
    "test_df  = df.iloc[n - test_size:].copy()\n",
    "\n",
    "X_train = train_df[features]\n",
    "y_train = train_df['PM2.5']\n",
    "X_test  = test_df[features]\n",
    "y_test  = test_df['PM2.5']\n",
    "\n",
    "print(\"Train:\", X_train.shape, \"Test:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b5eca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Missing values after imputation:\n",
      "Train: 0 Test: 0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np\n",
    "\n",
    "# Impute (fill) missing values in features\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "X_train = pd.DataFrame(imputer.fit_transform(X_train), columns=features)\n",
    "X_test = pd.DataFrame(imputer.transform(X_test), columns=features)\n",
    "\n",
    "# Just to confirm:\n",
    "print(\"✅ Missing values after imputation:\")\n",
    "print(\"Train:\", np.isnan(X_train.values).sum(), \"Test:\", np.isnan(X_test.values).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d7b668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression -> RMSE: 7.7607, R2: 0.4424\n",
      "RandomForest -> RMSE: 7.5511, R2: 0.5002\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'linear': {'rmse': 7.760700774543638, 'r2': 0.44238797498292237},\n",
       " 'rf': {'rmse': 7.551129424744999, 'r2': 0.5002232696278106}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import root_mean_squared_error, r2_score\n",
    "import os\n",
    "\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def eval_model(name, model, X_test, y_test):\n",
    "    preds = model.predict(X_test)\n",
    "    mse = root_mean_squared_error(y_test, preds) # squared=False Parameter removed\n",
    "    rmse = mse**0.5  # Calculate RMSE manually\n",
    "    r2 = r2_score(y_test, preds)\n",
    "    print(f\"{name} -> RMSE: {rmse:.4f}, R2: {r2:.4f}\")\n",
    "    return {\"rmse\": rmse, \"r2\": r2}\n",
    "\n",
    "results = {}\n",
    "\n",
    "# Linear Regression\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "results['linear'] = eval_model(\"LinearRegression\", lr, X_test, y_test)\n",
    "joblib.dump(lr, \"models/linear_reg.joblib\")\n",
    "\n",
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import gc\n",
    "\n",
    "rf = RandomForestRegressor(\n",
    "    n_estimators=100,       # fewer trees (cut memory ~½)\n",
    "    max_depth=20,           # limit depth to control tree size\n",
    "    n_jobs=-1,              # still use all cores\n",
    "    random_state=42\n",
    ")\n",
    "rf.fit(X_train, y_train)\n",
    "pred_rf = rf.predict(X_test)\n",
    "results['rf'] = eval_model(\"RandomForest\", rf, X_test, y_test)\n",
    "joblib.dump(rf, \"models/rf_reg.joblib\")\n",
    "\n",
    "gc.collect()   # free memory\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe4d3ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost -> RMSE: 7.4999, R2: 0.5137\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'linear': {'rmse': 7.760700774543638, 'r2': 0.44238797498292237},\n",
       " 'rf': {'rmse': 7.551129424744999, 'r2': 0.5002232696278106},\n",
       " 'xgb': {'rmse': 7.499889417578389, 'r2': 0.5136512374929307}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "# XGBoost\n",
    "xgr = xgb.XGBRegressor(n_estimators=300, tree_method='hist', random_state=42, verbosity=0)\n",
    "xgr.fit(X_train, y_train)\n",
    "results['xgb'] = eval_model(\"XGBoost\", xgr, X_test, y_test)\n",
    "xgr.save_model(\"models/xgb_reg.json\")\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e71a71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting protobuf==3.20.*\n",
      "  Using cached protobuf-3.20.3-py2.py3-none-any.whl.metadata (720 bytes)\n",
      "Using cached protobuf-3.20.3-py2.py3-none-any.whl (162 kB)\n",
      "Installing collected packages: protobuf\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 4.25.3\n",
      "    Uninstalling protobuf-4.25.3:\n",
      "      Successfully uninstalled protobuf-4.25.3\n",
      "Successfully installed protobuf-3.20.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-intel 2.18.0 requires opt-einsum>=2.3.2, which is not installed.\n"
     ]
    }
   ],
   "source": [
    "!pip install protobuf==3.20.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691cf1d5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjoblib\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# load data and model\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m df_all = \u001b[43mdf\u001b[49m.copy()   \u001b[38;5;66;03m# your cleaned dataframe in memory\u001b[39;00m\n\u001b[32m      9\u001b[39m model = joblib.load(\u001b[33m\"\u001b[39m\u001b[33mmodels/rf_reg.joblib\u001b[39m\u001b[33m\"\u001b[39m)  \u001b[38;5;66;03m# or use best model\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Regression fairness: MAE by Source and (if available) by City\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# governance_check.py (run in notebook cell or save as file and run)\n",
    "import pandas as pd\n",
    "import numpy as np, json\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import joblib\n",
    "\n",
    "# load data and model\n",
    "df_all = df.copy()   # your cleaned dataframe in memory\n",
    "model = joblib.load(\"models/rf_reg.joblib\")  # or use best model\n",
    "\n",
    "# Regression fairness: MAE by Source and (if available) by City\n",
    "df_all['pred'] = model.predict(df_all[features].fillna(df_all[features].median()))\n",
    "reg_mae_source = df_all.groupby('Source').apply(lambda g: mean_absolute_error(g['PM2.5'], g['pred'])).to_dict()\n",
    "reg_mae_city = df_all.groupby('City').apply(lambda g: mean_absolute_error(g['PM2.5'], g['pred'])) if 'City' in df_all.columns else None\n",
    "\n",
    "report = {\n",
    "    \"regression_mae_by_source\": reg_mae_source,\n",
    "    \"sample_top_cities_mae\": (reg_mae_city.sort_values(ascending=False).head(10).to_dict() if reg_mae_city is not None else {})\n",
    "}\n",
    "\n",
    "# AIF360 classification proxy (High vs NotHigh) + reweighing\n",
    "try:\n",
    "    from aif360.datasets import BinaryLabelDataset\n",
    "    from aif360.algorithms.preprocessing import Reweighing\n",
    "\n",
    "    df_clf = df_all.copy()\n",
    "    df_clf['label_high'] = (df_clf['PM2.5'] >= 60).astype(int)\n",
    "    df_clf['protected'] = (df_clf['Source'] == 'CityCombined').astype(int)\n",
    "    X = df_clf[features].fillna(df_clf[features].median())\n",
    "    data_for_aif = pd.DataFrame(np.hstack([X.values, df_clf['label_high'].values.reshape(-1,1), df_clf['protected'].values.reshape(-1,1)]),\n",
    "                                columns = [*features,'label','protected'])\n",
    "    dataset = BinaryLabelDataset(df=data_for_aif, label_names=['label'], protected_attribute_names=['protected'])\n",
    "    rw = Reweighing(unprivileged_groups=[{'protected':0}], privileged_groups=[{'protected':1}])\n",
    "    dataset_transf = rw.fit_transform(dataset)\n",
    "    # show weight summary\n",
    "    unique_weights = np.unique(dataset_transf.instance_weights)[:10].tolist()\n",
    "    report['aif360_weights_sample'] = unique_weights\n",
    "except Exception as e:\n",
    "    report['aif360_error'] = str(e)\n",
    "\n",
    "open(\"governance_report.json\",\"w\").write(json.dumps(report, indent=2))\n",
    "print(\"Saved governance_report.json\")\n",
    "print(report)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
